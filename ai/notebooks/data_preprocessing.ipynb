{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move some images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# define input and output directories\n",
    "input_dir = '/media/rodri/Files/Datasets/Final_Dataset/guns/train'\n",
    "output_dir = '/media/rodri/Files/Datasets/Final_Dataset/guns/output'\n",
    "\n",
    "# define number of images to select and move\n",
    "num_images = 4000\n",
    "\n",
    "# create output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "# get list of all image files in input directory\n",
    "image_files = [filename for filename in os.listdir(input_dir) if filename.endswith('.jpg')]\n",
    "\n",
    "# randomly select `num_images` image files\n",
    "selected_images = random.sample(image_files, num_images)\n",
    "\n",
    "# iterate over selected images, move them to output directory and find the corresponding annotations\n",
    "for filename in selected_images:\n",
    "    # move image file to output directory\n",
    "    src_path = os.path.join(input_dir, filename)\n",
    "    dst_path = os.path.join(output_dir, filename)\n",
    "    shutil.move(src_path, dst_path)\n",
    "\n",
    "    # find corresponding annotation file\n",
    "    annotation_filename = filename.replace('.jpg', '.xml')\n",
    "    annotation_src_path = os.path.join(input_dir, annotation_filename)\n",
    "    annotation_dst_path = os.path.join(output_dir, annotation_filename)\n",
    "\n",
    "    # move annotation file to output directory\n",
    "    shutil.move(annotation_src_path, annotation_dst_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# define input and output directories\n",
    "input_dir = '/media/rodri/Files/Datasets/Final_Dataset/knives/train'\n",
    "output_dir = '/media/rodri/Files/Datasets/Final_Dataset/knives/output'\n",
    "\n",
    "# define number of images to select and move\n",
    "num_images = 1540\n",
    "\n",
    "# create output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "# get list of all image files in input directory\n",
    "image_files = [filename for filename in os.listdir(input_dir) if filename.endswith('.jpg')]\n",
    "\n",
    "# randomly select `num_images` image files\n",
    "selected_images = random.sample(image_files, num_images)\n",
    "\n",
    "# iterate over selected images, move them to output directory and find the corresponding annotations\n",
    "for filename in selected_images:\n",
    "    # move image file to output directory\n",
    "    src_path = os.path.join(input_dir, filename)\n",
    "    dst_path = os.path.join(output_dir, filename)\n",
    "    shutil.move(src_path, dst_path)\n",
    "\n",
    "    # find corresponding annotation file\n",
    "    annotation_filename = filename.replace('.jpg', '.xml')\n",
    "    annotation_src_path = os.path.join(input_dir, annotation_filename)\n",
    "    annotation_dst_path = os.path.join(output_dir, annotation_filename)\n",
    "\n",
    "    # move annotation file to output directory\n",
    "    shutil.move(annotation_src_path, annotation_dst_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into folders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [03:08,  5.31it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_dir = '/media/rodri/Files/Datasets/Final_Dataset/guns/output'\n",
    "output_dir = '/media/rodri/Files/Datasets/Final_Dataset/guns/output2'\n",
    "batch_size = 4\n",
    "\n",
    "# create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "# define a generator that yields batches of files\n",
    "def batch_generator(file_list, batch_size):\n",
    "    for i in range(0, len(file_list), batch_size):\n",
    "        yield file_list[i:i+batch_size]\n",
    "\n",
    "# get a list of all image files in the input directory\n",
    "image_files = [filename for filename in os.listdir(input_dir) if filename.endswith('.jpg')]\n",
    "\n",
    "# use the batch generator to iterate over batches of files\n",
    "for i, file_batch in enumerate(tqdm(batch_generator(image_files, batch_size))):\n",
    "    # create a new folder for the batch\n",
    "    batch_dir = os.path.join(output_dir, f'batch_{i}')\n",
    "    os.mkdir(batch_dir)\n",
    "\n",
    "    # iterate over the image files in the batch\n",
    "    for filename in file_batch:\n",
    "        # copy the image file to the batch directory\n",
    "        src_path = os.path.join(input_dir, filename)\n",
    "        dst_path = os.path.join(batch_dir, filename)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "        # find the corresponding annotation file\n",
    "        annotation_filename = filename.replace('.jpg', '.xml')\n",
    "        annotation_src_path = os.path.join(input_dir, annotation_filename)\n",
    "        annotation_dst_path = os.path.join(batch_dir, annotation_filename)\n",
    "\n",
    "        # copy the annotation file to the batch directory\n",
    "        shutil.copy(annotation_src_path, annotation_dst_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "385it [01:10,  5.50it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_dir = '/media/rodri/Files/Datasets/Final_Dataset/knives/output'\n",
    "output_dir = '/media/rodri/Files/Datasets/Final_Dataset/knives/output2'\n",
    "batch_size = 4\n",
    "\n",
    "# create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "# define a generator that yields batches of files\n",
    "def batch_generator(file_list, batch_size):\n",
    "    for i in range(0, len(file_list), batch_size):\n",
    "        yield file_list[i:i+batch_size]\n",
    "\n",
    "# get a list of all image files in the input directory\n",
    "image_files = [filename for filename in os.listdir(input_dir) if filename.endswith('.jpg')]\n",
    "\n",
    "# use the batch generator to iterate over batches of files\n",
    "for i, file_batch in enumerate(tqdm(batch_generator(image_files, batch_size))):\n",
    "    # create a new folder for the batch\n",
    "    batch_dir = os.path.join(output_dir, f'batch_{i}')\n",
    "    os.mkdir(batch_dir)\n",
    "\n",
    "    # iterate over the image files in the batch\n",
    "    for filename in file_batch:\n",
    "        # copy the image file to the batch directory\n",
    "        src_path = os.path.join(input_dir, filename)\n",
    "        dst_path = os.path.join(batch_dir, filename)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "        # find the corresponding annotation file\n",
    "        annotation_filename = filename.replace('.jpg', '.xml')\n",
    "        annotation_src_path = os.path.join(input_dir, annotation_filename)\n",
    "        annotation_dst_path = os.path.join(batch_dir, annotation_filename)\n",
    "\n",
    "        # copy the annotation file to the batch directory\n",
    "        shutil.copy(annotation_src_path, annotation_dst_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:01<00:00,  5.52it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "input_dir = \"/media/rodri/Files/Datasets/Final_Dataset/guns/output2\"\n",
    "output_dir = \"/media/rodri/Files/Datasets/Final_Dataset/guns/output3\"\n",
    "size = 640\n",
    "\n",
    "def merge_image(folder_path, file_name, merged_image, x_offset, y_offset, idx):\n",
    "    # load the image and resize it\n",
    "    image_path = os.path.join(folder_path, file_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    resized_image = cv2.resize(image, (int(size/2), int(size/2)))\n",
    "    \n",
    "    # place the resized image on the merged image\n",
    "    merged_image[y_offset:y_offset+int(size/2), x_offset:x_offset+int(size/2)] = resized_image\n",
    "    \n",
    "    # update the x_offset and y_offset\n",
    "    x_offset += int(size/2)\n",
    "    if x_offset == size:\n",
    "        x_offset = 0\n",
    "        y_offset += int(size/2)\n",
    "        \n",
    "    return merged_image, x_offset, y_offset\n",
    "\n",
    "def generate_bounding_boxes_as_xml(folder_path, file_name, idx):\n",
    "    \n",
    "    tree = ET.parse(os.path.join(folder_path, file_name))\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    offsets = [\n",
    "        {'x': 0, 'y': 0},\n",
    "        {'x': int(size/2), 'y': 0},\n",
    "        {'x': 0, 'y': int(size/2)},\n",
    "        {'x': int(size/2), 'y': int(size/2)}\n",
    "    ]\n",
    "    \n",
    "    objects = []\n",
    "    for obj in root.findall('object'):\n",
    "        name = obj.find('name').text\n",
    "        pose = obj.find('pose').text if obj.find('pose') is not None else 'Unspecified'\n",
    "        truncated = obj.find('truncated').text if obj.find('truncated') is not None else 'Unspecified'\n",
    "        difficult = obj.find('difficult').text if obj.find('difficult') is not None else 'Unspecified'\n",
    "        bbox = obj.find('bndbox')\n",
    "        xmin = int(bbox.find('xmin').text)//2 + offsets[idx]['x']\n",
    "        xmax = int(bbox.find('xmax').text)//2 + offsets[idx]['x']\n",
    "        ymin = int(bbox.find('ymin').text)//2 + offsets[idx]['y']\n",
    "        ymax = int(bbox.find('ymax').text)//2 + offsets[idx]['y']\n",
    "        \n",
    "        objects.append({\n",
    "            'name': name,\n",
    "            'pose': pose,\n",
    "            'truncated': truncated,\n",
    "            'difficult': difficult,\n",
    "            'bbox': {\n",
    "                'xmin': xmin,\n",
    "                'xmax': xmax,\n",
    "                'ymin': ymin,\n",
    "                'ymax': ymax,\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    str_objects = \"\"\n",
    "    for obj in objects:\n",
    "        obj_str = \"\\t<object>\\n\"\n",
    "        for key, value in obj.items():\n",
    "            if key == 'bbox':\n",
    "                obj_str += \"\\t\\t<bndbox>\\n\"\n",
    "                for bbox_key, bbox_value in value.items():\n",
    "                    obj_str += f\"\\t\\t\\t<{bbox_key}>{bbox_value}</{bbox_key}>\\n\"\n",
    "                obj_str += \"\\t\\t</bndbox>\\n\"\n",
    "            else:\n",
    "                obj_str += f\"\\t\\t<{key}>{value}</{key}>\\n\"\n",
    "        obj_str += \"\\t</object>\\n\"\n",
    "        str_objects += obj_str\n",
    "    \n",
    "    return str_objects\n",
    "    \n",
    "def generate_string_xml_annotation_beginning(folder_path, file_name):\n",
    "    tree = ET.parse(os.path.join(folder_path, file_name))\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Change filename and path by folder name\n",
    "    root.find('filename').text = folder_path.split(\"/\")[-1] + \".jpg\"\n",
    "    # root.find('path').text = folder_path.split(\"/\")[-1] + \".jpg\"\n",
    "        \n",
    "    xml_string = ET.tostring(root).decode()\n",
    "    \n",
    "    return xml_string.split(\"<object>\")[0]\n",
    "\n",
    "def generate_string_xml_annotation_end(folder_path, file_name):\n",
    "    tree = ET.parse(os.path.join(folder_path, file_name))\n",
    "    root = tree.getroot()\n",
    "        \n",
    "    xml_string = ET.tostring(root).decode()\n",
    "        \n",
    "    return xml_string.split(\"</object>\")[-1]\n",
    "    \n",
    "\n",
    "def merge_images(folder_path, output_path):\n",
    "    # create a black merged image\n",
    "    merged_image = 255 * np.ones(shape=[size, size, 3], dtype=np.uint8)\n",
    "    x_offset = 0\n",
    "    y_offset = 0\n",
    "    \n",
    "    annotation = generate_string_xml_annotation_beginning(folder_path, os.listdir(folder_path)[1])\n",
    "    \n",
    "    # loop over the images in the folder\n",
    "    for idx, file_name in enumerate(os.listdir(folder_path)):\n",
    "        if file_name.endswith(\".jpg\"):\n",
    "            merged_image, x_offset, y_offset = merge_image(folder_path, file_name, merged_image, x_offset, y_offset, idx//2)\n",
    "            \n",
    "        if file_name.endswith(\".xml\"):\n",
    "            annotation += generate_bounding_boxes_as_xml(folder_path, file_name, idx//2)\n",
    "            \n",
    "    # save the merged images\n",
    "    output_image_path = os.path.join(output_path, folder_path.split(\"/\")[-1]+\".jpg\")\n",
    "    cv2.imwrite(output_image_path, merged_image)\n",
    "    \n",
    "    # save the merged annotations\n",
    "    annotation += generate_string_xml_annotation_end(folder_path, os.listdir(folder_path)[1])\n",
    "    with open(os.path.join(output_path, folder_path.split(\"/\")[-1]+\".xml\"), \"w\") as f:\n",
    "        f.write(annotation)\n",
    "    \n",
    "\n",
    "# create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# use a generator to iterate over the folders in the directory and call the merge_images function for each folder\n",
    "for input_path in tqdm(os.listdir(input_dir)):\n",
    "    input_path = os.path.join(input_dir, input_path)\n",
    "    if os.path.isdir(input_path):\n",
    "        # merge the images in the folder\n",
    "        merge_images(input_path, output_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:31<00:00, 12.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "input_dir = \"/media/rodri/Files/Datasets/Final_Dataset/knives/output2\"\n",
    "output_dir = \"/media/rodri/Files/Datasets/Final_Dataset/knives/output3\"\n",
    "size = 640\n",
    "\n",
    "def merge_image(folder_path, file_name, merged_image, x_offset, y_offset, idx):\n",
    "    # load the image and resize it\n",
    "    image_path = os.path.join(folder_path, file_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    resized_image = cv2.resize(image, (int(size/2), int(size/2)))\n",
    "    \n",
    "    # place the resized image on the merged image\n",
    "    merged_image[y_offset:y_offset+int(size/2), x_offset:x_offset+int(size/2)] = resized_image\n",
    "    \n",
    "    # update the x_offset and y_offset\n",
    "    x_offset += int(size/2)\n",
    "    if x_offset == size:\n",
    "        x_offset = 0\n",
    "        y_offset += int(size/2)\n",
    "        \n",
    "    return merged_image, x_offset, y_offset\n",
    "\n",
    "def generate_bounding_boxes_as_xml(folder_path, file_name, idx):\n",
    "    tree = ET.parse(os.path.join(folder_path, file_name))\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    offsets = [\n",
    "        {'x': 0, 'y': 0},\n",
    "        {'x': int(size/2), 'y': 0},\n",
    "        {'x': 0, 'y': int(size/2)},\n",
    "        {'x': int(size/2), 'y': int(size/2)}\n",
    "    ]\n",
    "    \n",
    "    objects = []\n",
    "    for obj in root.findall('object'):\n",
    "        name = obj.find('name').text\n",
    "        pose = obj.find('pose').text\n",
    "        truncated = obj.find('truncated').text\n",
    "        difficult = obj.find('difficult').text\n",
    "        bbox = obj.find('bndbox')\n",
    "        xmin = int(bbox.find('xmin').text)//2 + offsets[idx]['x']\n",
    "        xmax = int(bbox.find('xmax').text)//2 + offsets[idx]['x']\n",
    "        ymin = int(bbox.find('ymin').text)//2 + offsets[idx]['y']\n",
    "        ymax = int(bbox.find('ymax').text)//2 + offsets[idx]['y']\n",
    "        \n",
    "        objects.append({\n",
    "            'name': name,\n",
    "            'pose': pose,\n",
    "            'truncated': truncated,\n",
    "            'difficult': difficult,\n",
    "            'bbox': {\n",
    "                'xmin': xmin,\n",
    "                'xmax': xmax,\n",
    "                'ymin': ymin,\n",
    "                'ymax': ymax,\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    str_objects = \"\"\n",
    "    for obj in objects:\n",
    "        obj_str = \"\\t<object>\\n\"\n",
    "        for key, value in obj.items():\n",
    "            if key == 'bbox':\n",
    "                obj_str += \"\\t\\t<bndbox>\\n\"\n",
    "                for bbox_key, bbox_value in value.items():\n",
    "                    obj_str += f\"\\t\\t\\t<{bbox_key}>{bbox_value}</{bbox_key}>\\n\"\n",
    "                obj_str += \"\\t\\t</bndbox>\\n\"\n",
    "            else:\n",
    "                obj_str += f\"\\t\\t<{key}>{value}</{key}>\\n\"\n",
    "        obj_str += \"\\t</object>\\n\"\n",
    "        str_objects += obj_str\n",
    "    \n",
    "    return str_objects\n",
    "    \n",
    "def generate_string_xml_annotation_beginning(folder_path, file_name):\n",
    "    tree = ET.parse(os.path.join(folder_path, file_name))\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Change filename and path by folder name\n",
    "    root.find('filename').text = folder_path.split(\"/\")[-1] + \".jpg\"\n",
    "    root.find('path').text = folder_path.split(\"/\")[-1] + \".jpg\"\n",
    "        \n",
    "    xml_string = ET.tostring(root).decode()\n",
    "    \n",
    "    return xml_string.split(\"<object>\")[0]\n",
    "\n",
    "def generate_string_xml_annotation_end(folder_path, file_name):\n",
    "    tree = ET.parse(os.path.join(folder_path, file_name))\n",
    "    root = tree.getroot()\n",
    "        \n",
    "    xml_string = ET.tostring(root).decode()\n",
    "        \n",
    "    return xml_string.split(\"</object>\")[-1]\n",
    "    \n",
    "\n",
    "def merge_images(folder_path, output_path):\n",
    "    # create a black merged image\n",
    "    merged_image = 255 * np.ones(shape=[size, size, 3], dtype=np.uint8)\n",
    "    x_offset = 0\n",
    "    y_offset = 0\n",
    "    \n",
    "    annotation = generate_string_xml_annotation_beginning(folder_path, os.listdir(folder_path)[1])\n",
    "    \n",
    "    # loop over the images in the folder\n",
    "    for idx, file_name in enumerate(os.listdir(folder_path)):\n",
    "        if file_name.endswith(\".jpg\"):\n",
    "            merged_image, x_offset, y_offset = merge_image(folder_path, file_name, merged_image, x_offset, y_offset, idx//2)\n",
    "            \n",
    "        if file_name.endswith(\".xml\"):\n",
    "            annotation += generate_bounding_boxes_as_xml(folder_path, file_name, idx//2)\n",
    "            \n",
    "    # save the merged images\n",
    "    output_image_path = os.path.join(output_path, folder_path.split(\"/\")[-1]+\".jpg\")\n",
    "    cv2.imwrite(output_image_path, merged_image)\n",
    "    \n",
    "    # save the merged annotations\n",
    "    annotation += generate_string_xml_annotation_end(folder_path, os.listdir(folder_path)[1])\n",
    "    with open(os.path.join(output_path, folder_path.split(\"/\")[-1]+\".xml\"), \"w\") as f:\n",
    "        f.write(annotation)\n",
    "    \n",
    "\n",
    "# create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# use a generator to iterate over the folders in the directory and call the merge_images function for each folder\n",
    "for input_path in tqdm(os.listdir(input_dir)):\n",
    "    input_path = os.path.join(input_dir, input_path)\n",
    "    if os.path.isdir(input_path):\n",
    "        # merge the images in the folder\n",
    "        merge_images(input_path, output_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge results and clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying train: 8000it [05:32, 24.02it/s]\n",
      "Copying output3: 2000it [01:11, 27.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in upload folder: 10000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_path = '/media/rodri/Files/Datasets/Final_Dataset/guns'\n",
    "\n",
    "# Create upload folder\n",
    "os.makedirs(f\"{input_path}/upload\", exist_ok=True)\n",
    "\n",
    "# Folder generator\n",
    "def file_generator(folder_path):\n",
    "    for file in os.listdir(folder_path):\n",
    "        yield file\n",
    "\n",
    "# Copy all content of train and output3 to upload\n",
    "for file in tqdm(file_generator(f\"{input_path}/train\"), desc=\"Copying train\"):\n",
    "    shutil.copy(f\"{input_path}/train/{file}\", f\"{input_path}/upload\")\n",
    "for file in tqdm(file_generator(f\"{input_path}/output3\"), desc=\"Copying output3\"):\n",
    "    shutil.copy(f\"{input_path}/output3/{file}\", f\"{input_path}/upload\")\n",
    "\n",
    "# Remove all generated folders\n",
    "shutil.rmtree(f\"{input_path}/train\")\n",
    "shutil.rmtree(f\"{input_path}/output\")\n",
    "shutil.rmtree(f\"{input_path}/output2\")\n",
    "shutil.rmtree(f\"{input_path}/output3\")\n",
    "\n",
    "# Print the number of files in the upload folder\n",
    "print(f\"Number of files in upload folder: {len(os.listdir(f'{input_path}/upload'))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying train: 9226it [04:03, 37.86it/s] \n",
      "Copying output3: 770it [00:30, 25.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in upload folder: 9996\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_path = '/media/rodri/Files/Datasets/Final_Dataset/knives'\n",
    "\n",
    "# Create upload folder\n",
    "os.makedirs(f\"{input_path}/upload\", exist_ok=True)\n",
    "\n",
    "# Folder generator\n",
    "def file_generator(folder_path):\n",
    "    for file in os.listdir(folder_path):\n",
    "        yield file\n",
    "\n",
    "# Copy all content of train and output3 to upload\n",
    "for file in tqdm(file_generator(f\"{input_path}/train\"), desc=\"Copying train\"):\n",
    "    shutil.copy(f\"{input_path}/train/{file}\", f\"{input_path}/upload\")\n",
    "for file in tqdm(file_generator(f\"{input_path}/output3\"), desc=\"Copying output3\"):\n",
    "    shutil.copy(f\"{input_path}/output3/{file}\", f\"{input_path}/upload\")\n",
    "\n",
    "# Remove all generated folders\n",
    "shutil.rmtree(f\"{input_path}/train\")\n",
    "shutil.rmtree(f\"{input_path}/output\")\n",
    "shutil.rmtree(f\"{input_path}/output2\")\n",
    "shutil.rmtree(f\"{input_path}/output3\")\n",
    "\n",
    "# Print the number of files in the upload folder\n",
    "print(f\"Number of files in upload folder: {len(os.listdir(f'{input_path}/upload'))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split upload folder into four batches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting upload: 10000it [03:14, 51.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_path = '/media/rodri/Files/Datasets/Final_Dataset/guns/new_upload'\n",
    "output_path = '/media/rodri/Files/Datasets/Final_Dataset/guns/upload_split'\n",
    "threshold = 0\n",
    "\n",
    "# Create upload_split folder\n",
    "os.makedirs(f\"{output_path}\", exist_ok=True)\n",
    "\n",
    "# Folder generator\n",
    "def file_generator(folder_path):\n",
    "    for idx, file in enumerate(os.listdir(folder_path)):\n",
    "        yield idx, file\n",
    "\n",
    "# Split upload folder into 4 folders\n",
    "for idx, file in tqdm(file_generator(f\"{input_path}\"), desc=\"Splitting upload\"):\n",
    "    if idx == threshold:\n",
    "        threshold += 2500\n",
    "        os.makedirs(f\"{output_path}/batch_{threshold//2500}/\", exist_ok=True)\n",
    "    shutil.copy(f\"{input_path}/{file}\", f\"{output_path}/batch_{threshold//2500}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting upload: 9996it [04:15, 39.17it/s] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_path = '/media/rodri/Files/Datasets/Final_Dataset/knives/upload'\n",
    "output_path = '/media/rodri/Files/Datasets/Final_Dataset/knives/upload_split'\n",
    "threshold = 0\n",
    "\n",
    "# Create upload_split folder\n",
    "os.makedirs(f\"{output_path}\", exist_ok=True)\n",
    "\n",
    "# Folder generator\n",
    "def file_generator(folder_path):\n",
    "    for idx, file in enumerate(os.listdir(folder_path)):\n",
    "        yield idx, file\n",
    "\n",
    "# Split upload folder into 4 folders\n",
    "for idx, file in tqdm(file_generator(f\"{input_path}\"), desc=\"Splitting upload\"):\n",
    "    if idx == threshold:\n",
    "        threshold += 2500\n",
    "        os.makedirs(f\"{output_path}/batch_{threshold//2500}/\", exist_ok=True)\n",
    "    shutil.copy(f\"{input_path}/{file}\", f\"{output_path}/batch_{threshold//2500}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
